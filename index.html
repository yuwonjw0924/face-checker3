<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>顔面偏差値診断 - 詳細解析版</title>

  <style>
    :root{--bg:#f3f8ff;--card:#ffffff;--accent:#0b74d1}
    body{font-family:system-ui,-apple-system,"Hiragino Kaku Gothic ProN","Segoe UI",Roboto,Helvetica,Arial; margin:0; padding:20px; background:var(--bg); color:#122;}
    .wrap{max-width:980px;margin:0 auto;display:flex;gap:20px;flex-wrap:wrap}
    .card{background:var(--card);border-radius:12px;padding:16px;box-shadow:0 6px 18px rgba(10,30,60,0.06);flex:1;min-width:300px}
    h1{margin:0 0 10px 0;color:var(--accent)}
    .controls{display:flex;gap:8px;flex-wrap:wrap;margin-bottom:10px}
    button,input[type=file]{padding:10px 12px;border-radius:8px;border:1px solid #ddd;background:#fff;cursor:pointer}
    video,canvas{width:320px;height:auto;border-radius:8px;background:#000;display:block}
    #status{font-size:0.95rem;color:#444;margin-bottom:8px}
    .scoreBig{font-size:2.2rem;font-weight:700;color:#0b74d1}
    .parts{margin-top:12px}
    .part{display:flex;justify-content:space-between;padding:6px 0;border-bottom:1px dashed #eee}
    .comment{margin-top:10px;background:#fbfdff;padding:10px;border-radius:8px;border:1px solid #eef; color:#234}
    .warn{color:#b03;font-weight:600}
    small{color:#666}
  </style>

  <!-- face-api.js CDN -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
</head>
<body>
  <div class="wrap">
    <div class="card" style="max-width:360px">
      <h1>顔面偏差値診断（詳細）</h1>
      <div id="status">モデル読み込み中… <small>(初回は時間がかかります)</small></div>

      <div class="controls">
        <button id="startCam" >カメラ開始 / 停止</button>
        <button id="capture" disabled>撮る（解析）</button>
        <input id="file" type="file" accept="image/*">
      </div>

      <video id="video" autoplay muted playsinline style="display:none"></video>
      <canvas id="canvas" width="640" height="480" style="display:block;margin-top:10px"></canvas>

      <div style="margin-top:8px">
        <small class="warn">※ 画像はブラウザ内で処理され、デフォルトで外部に送信されません。結果は参考用です。</small>
      </div>
    </div>

    <div class="card">
      <h1>診断結果</h1>
      <div id="resultArea">
        <div id="overall" style="display:flex;align-items:baseline;gap:14px">
          <div class="scoreBig" id="score">--</div>
          <div>
            <div>顔面偏差値</div>
            <small id="subText">解析を実行してください</small>
          </div>
        </div>

        <div class="parts" id="parts" style="display:none">
          <div class="part"><div>対称性</div><div id="sym">-- / 40</div></div>
          <div class="part"><div>黄金比適合度</div><div id="gold">-- / 30</div></div>
          <div class="part"><div>パーツ比率整合度</div><div id="prop">-- / 20</div></div>
          <div class="part"><div>目・口バランス</div><div id="eyes">-- / 10</div></div>
        </div>

        <div class="comment" id="comment" style="display:none"></div>
      </div>
    </div>
  </div>

<script>
(async ()=>{

  const statusEl = document.getElementById('status');
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  const startCamBtn = document.getElementById('startCam');
  const captureBtn = document.getElementById('capture');
  const fileInput = document.getElementById('file');

  const scoreEl = document.getElementById('score');
  const subText = document.getElementById('subText');
  const partsDiv = document.getElementById('parts');
  const symEl = document.getElementById('sym');
  const goldEl = document.getElementById('gold');
  const propEl = document.getElementById('prop');
  const eyesEl = document.getElementById('eyes');
  const commentEl = document.getElementById('comment');

  // モデル読み込み（CDN weights）
  async function loadModels(){
    try {
      const base = "https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/";
      statusEl.textContent = "モデル読み込み中…";
      await faceapi.nets.tinyFaceDetector.loadFromUri(base);
      await faceapi.nets.faceLandmark68Net.loadFromUri(base);
      statusEl.textContent = "モデル準備完了！ カメラを開始するか画像を選択してください。";
      captureBtn.disabled = false;
    } catch (e) {
      console.error(e);
      statusEl.innerHTML = 'モデルの読み込みに失敗しました。ネット接続を確認してください。';
    }
  }

  await loadModels();

  // カメラ開始 / 停止
  let stream = null;
  startCamBtn.addEventListener('click', async ()=>{
    if (stream) {
      stream.getTracks().forEach(t=>t.stop());
      stream = null;
      video.style.display = 'none';
      startCamBtn.textContent = 'カメラ開始 / 停止';
      captureBtn.disabled = true;
      return;
    }
    try {
      stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
      video.srcObject = stream;
      video.style.display = 'block';
      startCamBtn.textContent = 'カメラ停止';
      captureBtn.disabled = false;
    } catch (e) {
      statusEl.textContent = 'カメラが許可されていません。ブラウザの設定を確認してください。';
      console.error(e);
    }
  });

  // ユーティリティ
  const dist = (a,b) => Math.hypot(a.x-b.x, a.y-b.y);
  const mean = arr => arr.reduce((s,v)=>s+v,0)/arr.length;

  // タイムアウト付き検出（解析中で止まらないように）
  async function detectWithTimeout(input, timeoutMs=8000){
    const detectPromise = faceapi.detectSingleFace(input, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
    const timeoutPromise = new Promise((_, rej)=> setTimeout(()=> rej(new Error('timeout')), timeoutMs));
    return Promise.race([detectPromise, timeoutPromise]);
  }

  // 画像から診断
  async function analyzeImage(img){
    try {
      statusEl.textContent = '解析中…';
      // 表示
      canvas.width = img.width;
      canvas.height = img.height;
      ctx.clearRect(0,0,canvas.width,canvas.height);
      ctx.drawImage(img, 0, 0);

      let detection;
      try {
        detection = await detectWithTimeout(img, 8000);
      } catch (e) {
        console.warn('検出タイムアウトやエラー', e);
        statusEl.textContent = '顔検出に失敗しました（タイムアウト）。別の画像で試してください。';
        return;
      }
      if(!detection){
        statusEl.textContent = '顔が検出できませんでした。顔がはっきり写っている画像を選んでください。';
        return;
      }

      const resized = faceapi.resizeResults(detection, { width: canvas.width, height: canvas.height });
      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceLandmarks(canvas, resized);

      // ランドマーク点
      const lm = resized.landmarks;
      const pts = lm.positions; // 68 points

      // 基本距離（正規化用）: 顔幅（左右の顎の距離）
      const faceWidth = dist(pts[1], pts[15]) || 1;
      const faceHeight = dist(pts[8], pts[27]) || 1;

      // 1) 対称性スコア (0-40)
      // 左右対応点の鏡映差を測る（目/鼻翼/口/頬あたり）
      const pairs = [[36,45],[39,42],[31,35],[48,54],[2,14],[3,13]];
      // 中心線 x:  between nose bridge and mid eyes
      const leftEyeCx = mean(lm.getLeftEye().map(p=>p.x));
      const rightEyeCx = mean(lm.getRightEye().map(p=>p.x));
      const midX = (leftEyeCx + rightEyeCx)/2;
      let asymSum = 0;
      pairs.forEach(([i,j])=>{
        const li = pts[i], rj = pts[j];
        const refl = { x: midX + (midX - li.x), y: li.y };
        asymSum += dist(refl, rj);
      });
      const asymMean = asymSum / pairs.length;
      const asymNorm = Math.min(1, asymMean / faceWidth); // 小さいほど良い
      const symmetryScore = Math.round((1 - asymNorm) * 40);

      // 2) 黄金比適合度 (0-30)
      // 代表比率: faceHeight/faceWidth, interEye/faceWidth, noseLength/faceHeight
      const interEye = dist({x:mean(lm.getLeftEye().map(p=>p.x)), y:mean(lm.getLeftEye().map(p=>p.y))},
                            {x:mean(lm.getRightEye().map(p=>p.x)), y:mean(lm.getRightEye().map(p=>p.y))}) || 1;
      const noseTop = pts[27], noseTip = pts[30], chin = pts[8];
      const noseLen = dist(noseTop, noseTip) + 0.0001;
      const ratioA = faceHeight/faceWidth;
      const ratioB = interEye/faceWidth;
      const ratioC = noseLen/faceHeight;
      // それぞれの理想値（参考値）を決めて相対誤差を計測
      const idealA = 1.6; // 顔縦横
      const idealB = 0.32; // 目間/顔幅（経験値）
      const idealC = 0.18; // 鼻長/顔長
      const errA = Math.min(1, Math.abs(ratioA - idealA)/idealA);
      const errB = Math.min(1, Math.abs(ratioB - idealB)/idealB);
      const errC = Math.min(1, Math.abs(ratioC - idealC)/idealC);
      const goldScore = Math.round((1 - (errA*0.5 + errB*0.3 + errC*0.2)) * 30);

      // 3) パーツ比率整合度 (0-20)
      // 目の大きさ・左右差 / 口幅と目間の比などを評価
      const leftEyeSize = mean(lm.getLeftEye().map((p,i,arr)=>dist(p, arr[(i+3)%arr.length])));
      const rightEyeSize = mean(lm.getRightEye().map((p,i,arr)=>dist(p, arr[(i+3)%arr.length])));
      const eyeSizeDiff = Math.abs(leftEyeSize - rightEyeSize) / Math.max(leftEyeSize, rightEyeSize);
      const mouthWidth = dist(pts[48], pts[54]) || 1;
      const propErr = Math.min(1, Math.abs((mouthWidth/faceWidth) - 0.45) / 0.45); // mouth/faceWidth ideal~0.45
      const propScore = Math.round((1 - (eyeSizeDiff*0.6 + propErr*0.4)) * 20);

      // 4) 目・口バランス (0-10)
      // 目と口の高さ傾きや口角差を評価
      const leftEyeY = mean(lm.getLeftEye().map(p=>p.y));
      const rightEyeY = mean(lm.getRightEye().map(p=>p.y));
      const eyeYDiff = Math.abs(leftEyeY - rightEyeY) / faceHeight;
      const mouthCornerY = (pts[48].y + pts[54].y)/2;
      const mouthTilt = Math.abs(((pts[48].y - pts[54].y))) / faceWidth;
      const eyesScore = Math.round((1 - Math.min(1, (eyeYDiff*0.7 + mouthTilt*0.3))) * 10);

      // 合計
      let total = symmetryScore + goldScore + propScore + eyesScore;
      total = Math.max(0, Math.min(100, Math.round(total)));

      // 偏差値化（任意）：ここでは単純スコアを表示。偏差値表示にしたい場合は平均と分散で変換。
      scoreEl.textContent = total;
      subText.textContent = `解析完了 — 顔幅=${Math.round(faceWidth)}, 縦=${Math.round(faceHeight)}`;
      partsDiv.style.display = 'block';
      symEl.textContent = `${symmetryScore} / 40`;
      goldEl.textContent = `${goldScore} / 30`;
      propEl.textContent = `${propScore} / 20`;
      eyesEl.textContent = `${eyesScore} / 10`;
      commentEl.style.display = 'block';

      // コメント作成（簡易ルールベース）
      let comments = [];
      if (symmetryScore >= 32) comments.push("左右のバランスが良好です。顔の印象が安定しています。");
      else if (symmetryScore >= 20) comments.push("多少の左右差がありますが自然な範囲です。");
      else comments.push("左右差が気になります。髪型や角度で印象が変わりやすいです。");

      if (goldScore >= 24) comments.push("黄金比に近い比率です。整った印象を与えやすいです。");
      else if (goldScore >= 12) comments.push("一部比率は良好ですが改善余地があります。");
      else comments.push("比率が理想値からずれています。撮影角度や表情で変わる可能性があります。");

      if (propScore < 10) comments.push("目のサイズ差や口の比率でややアンバランスです。メイクや角度で整います。");
      if (eyesScore < 6) comments.push("目の高さ差や口角の傾きが見られます。自然な笑顔で印象が良くなることが多いです.");

      // 総合アドバイス
      if (total >= 80) comments.unshift("総合的に非常にバランスの良い顔立ちです！");
      else if (total >= 65) comments.unshift("総合的に好印象。細かい部分でさらに磨けます。");
      else if (total >= 45) comments.unshift("平均的なバランス。写真の角度でスコアが大きく変わることがあります。");
      else comments.unshift("改善ポイントが複数あります。照明・角度・表情を工夫してみましょう。");

      commentEl.innerHTML = comments.map(c=>`<div>・${c}</div>`).join('');

      statusEl.textContent = '解析完了';
    } catch (err) {
      console.error(err);
      statusEl.textContent = '解析中にエラーが発生しました。コンソールを確認してください。';
    }
  }

  // capture from camera
  captureBtn.addEventListener('click', async ()=>{
    if (video.style.display !== 'block' || !video.srcObject) {
      // video not active => maybe analyze current canvas image (if file loaded)
      const img = new Image();
      img.src = canvas.toDataURL('image/png');
      img.onload = ()=> analyzeImage(img);
      return;
    }
    // draw current video frame to canvas then analyze
    try {
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const img = new Image();
      img.src = canvas.toDataURL('image/png');
      img.onload = ()=> analyzeImage(img);
    } catch (e) {
      console.error(e);
      statusEl.textContent = 'カメラ画像の取得に失敗しました。';
    }
  });

  // file input
  fileInput.addEventListener('change', async (ev)=>{
    const f = ev.target.files[0];
    if (!f) return;
    const img = await faceapi.bufferToImage(f);
    // resize large images for performance
    const maxW = 1200;
    let w = img.width, h = img.height;
    if (w > maxW) {
      const scale = maxW / w; w = Math.round(w*scale); h = Math.round(h*scale);
      const tmp = document.createElement('canvas'); tmp.width=w; tmp.height=h; tmp.getContext('2d').drawImage(img,0,0,w,h);
      const resizedImg = new Image();
      resizedImg.src = tmp.toDataURL('image/png');
      resizedImg.onload = ()=> analyzeImage(resizedImg);
    } else {
      analyzeImage(img);
    }
  });

})();
</script>
</body>
</html>


  